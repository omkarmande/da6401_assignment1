{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO9p9MG8cKilZmlmqAzyer0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/omkarmande/da6401_assignment1/blob/main/Question2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "oRRoLFYwFDkv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.datasets import fashion_mnist\n",
        "import wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wandb login"
      ],
      "metadata": {
        "id": "s3U-alXiFFeq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "350ca0f8-1b98-435d-9a95-7e167a7769ec"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit: \n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33momkarmande\u001b[0m (\u001b[33momkarmande-iit-madras\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "X_train = X_train.reshape(X_train.shape[0], -1) / 255.0\n",
        "X_test = X_test.reshape(X_test.shape[0], -1) / 255.0\n",
        "\n",
        "num_classes = 10\n",
        "y_train_onehot = np.eye(num_classes)[y_train]\n",
        "y_test_onehot = np.eye(num_classes)[y_test]\n",
        "\n",
        "split_index = int(0.9 * X_train.shape[0])\n",
        "X, X_val = X_train[:split_index], X_train[split_index:]\n",
        "y, y_val = y_train_onehot[:split_index], y_train_onehot[split_index:]"
      ],
      "metadata": {
        "id": "KYoQDNXPFHxx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76480547-9034-4562-ecfd-66623d38c648"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def sigmoid(x):\n",
        "    x = np.clip(x, -500, 500)\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def sigmoid_derivative(x):\n",
        "    return sigmoid(x) * (1 - sigmoid(x))\n",
        "\n",
        "def tanh(x):\n",
        "    x = np.clip(x, -500, 500)\n",
        "    return np.tanh(x)\n",
        "\n",
        "def tanh_derivative(x):\n",
        "    return 1 - np.tanh(x) ** 2\n",
        "\n",
        "def identity(x):\n",
        "    return x\n",
        "\n",
        "def identity_derivative(x):\n",
        "    return np.ones_like(x)\n",
        "\n",
        "def relu(x):\n",
        "    return np.maximum(0, x)\n",
        "\n",
        "def relu_derivative(x):\n",
        "    return (x > 0).astype(float)\n",
        "\n",
        "def softmax(x):\n",
        "    x = x - np.max(x, axis=1, keepdims=True)\n",
        "    exp_x = np.exp(x)\n",
        "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n"
      ],
      "metadata": {
        "id": "xT-d031xFKwd"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cross_entropy_loss(y_true, y_pred):\n",
        "    return -np.sum(y_true * np.log(y_pred + 1e-9)) / y_true.shape[0]\n",
        "\n",
        "def squared_error_loss(y_true, y_pred):\n",
        "    return np.mean(np.sum((y_true - y_pred) ** 2, axis=1))\n",
        "\n",
        "def accuracy(y_true, y_pred):\n",
        "    true_labels = np.argmax(y_true, axis=1)\n",
        "    pred_labels = np.argmax(y_pred, axis=1)\n",
        "    return np.mean(true_labels == pred_labels)"
      ],
      "metadata": {
        "id": "7ATGPV3AIQ2Y"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def initialize_weights(shape, method=\"xavier\"):\n",
        "    if method == \"random\":\n",
        "        return np.random.randn(*shape) * 0.01\n",
        "    elif method == \"xavier\":\n",
        "        return np.random.randn(*shape) * np.sqrt(2.0 / shape[0])\n",
        "    else:\n",
        "        raise ValueError(\"Unknown initialization method: Choose 'random' or 'xavier'\")\n",
        "\n",
        "def clip_gradients(grads, clip_value=5.0):\n",
        "    return [np.clip(g, -clip_value, clip_value) for g in grads]"
      ],
      "metadata": {
        "id": "_ykTFULpFRBK"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model:\n",
        "  def get_activation_functions(self, activation_type):\n",
        "        activations = {\n",
        "            \"sigmoid\": (sigmoid, sigmoid_derivative),\n",
        "            \"tanh\": (tanh, tanh_derivative),\n",
        "            \"ReLu\": (relu, relu_derivative),\n",
        "            \"identity\": (identity, identity_derivative)\n",
        "        }\n",
        "        return activations.get(activation_type, (sigmoid, sigmoid_derivative))\n",
        "\n",
        "  def __init__(self, il_neuron, hl_neuron, hl_count, ol_neuron, opt=\"adam\", lr=0.1, batch=4, init=\"xavier\", act=\"tanh\", loss=\"cross_entropy\", decay=0):\n",
        "    self.layers = [il_neuron] + [hl_neuron]*hl_count + [ol_neuron]\n",
        "    self.weights = []\n",
        "    self.biases = []\n",
        "    self.opt = opt\n",
        "    self.lr = lr\n",
        "    self.batch = batch\n",
        "    self.init = init\n",
        "    self.act = act\n",
        "    self.loss = loss\n",
        "    self.decay = decay\n",
        "    self.momentum = 0.9\n",
        "    self.beta1 = 0.9\n",
        "    self.beta2 = 0.999\n",
        "    self.epsilon = 1e-6\n",
        "    self.t = 0\n",
        "\n",
        "    self.velocities = []\n",
        "    self.velocities_b = []\n",
        "    self.squared_grads = []\n",
        "    self.squared_grads_b = []\n",
        "    self.m_t_w = []\n",
        "    self.m_t_b = []\n",
        "    self.v_t_w = []\n",
        "    self.v_t_b = []\n",
        "\n",
        "    self.activation_func, self.activation_derivative = self.get_activation_functions(act)\n",
        "    self.loss_func = cross_entropy_loss if loss == \"cross_entropy\" else squared_error_loss\n",
        "\n",
        "    #initializing and giving shape\n",
        "    for i in range(len(self.layers) - 1):\n",
        "        weight_matrix = initialize_weights((self.layers[i], self.layers[i + 1]), method=self.init)\n",
        "        bias_vector = np.zeros((1, self.layers[i + 1]))\n",
        "        self.weights.append(weight_matrix)\n",
        "        self.biases.append(bias_vector)\n",
        "\n",
        "  def feedForward(self, X):\n",
        "    activations = [X]\n",
        "    for i in range(len(self.weights) - 1):\n",
        "      z = np.dot(activations[-1], self.weights[i]) + self.biases[i]\n",
        "      #print(z.shape)\n",
        "      a = self.activation_func(z)\n",
        "      activations.append(a)\n",
        "\n",
        "    z_output = np.dot(activations[-1], self.weights[-1]) + self.biases[-1]\n",
        "    a_output = softmax(z_output)\n",
        "    activations.append(a_output)\n",
        "\n",
        "    return activations"
      ],
      "metadata": {
        "id": "6b8dy2ecFahW"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nn = Model(il_neuron=784, hl_neuron=32, hl_count=3, ol_neuron=10, opt=\"adam\", lr=0.1, batch=4, init=\"xavier\", act=\"tanh\", loss=\"cross_entropy\", decay=0)\n",
        "\n",
        "sample_X = X_test[:5]\n",
        "outputs = nn.feedForward(sample_X)\n",
        "\n",
        "print(\"Output probabilities for first five test image:\")\n",
        "#print(outputs[-1][0])\n",
        "#print(\"done\")\n",
        "print(outputs[-1][:5])"
      ],
      "metadata": {
        "id": "kko0MRGVF7Cw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd35d501-6eb3-4f14-e04f-2b9e98097785"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output probabilities for first five test image:\n",
            "[[0.12154883 0.06586419 0.15177749 0.08443134 0.16502852 0.09659045\n",
            "  0.03040004 0.07151684 0.16620973 0.04663256]\n",
            " [0.03656215 0.08834436 0.31016818 0.05636596 0.08922732 0.0338922\n",
            "  0.08587661 0.08191317 0.18929211 0.02835794]\n",
            " [0.01823558 0.10683912 0.10427081 0.07817903 0.20175652 0.05956385\n",
            "  0.14077919 0.03456315 0.0993896  0.15642313]\n",
            " [0.02006977 0.07671915 0.20199922 0.04642982 0.10668177 0.04459541\n",
            "  0.18718983 0.03580323 0.16978642 0.11072537]\n",
            " [0.03900815 0.1262285  0.20837766 0.07683751 0.14389917 0.03465189\n",
            "  0.10072354 0.05341146 0.16022804 0.05663408]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Kapc2kqSIbDu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}